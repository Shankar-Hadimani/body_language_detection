{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d81761-b4f9-4701-9a7b-4819708f9596",
   "metadata": {},
   "source": [
    "# 0. Install dependencies and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f008e57e-08b2-4348-8451-ded2e3f97179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (0.8.3.1)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (4.5.1.48)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (1.2.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (0.24.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (1.20.2)\n",
      "Requirement already satisfied: wheel in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (3.15.8)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (0.12.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: dataclasses in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from mediapipe) (0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from scikit-learn) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/aibd/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daef2263-f70f-40b4-a5bd-05d3cf8e95d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Disable jedi autocompleter\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b780cdf0-4ad3-4a84-8fbb-0c5f5ef7d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c37e330-3b5a-4429-9fb3-c32f3129abfa",
   "metadata": {},
   "source": [
    " # 1. Make Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ac9966-5730-473c-9509-fb6ae5f97d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # number varies with cameras\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor the image to RGB from BGR, as mediapipe expects it\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Make detections\n",
    "        image_rgb.flags.writeable = False  # for perofmance enhancement for holistic model\n",
    "        results = holistic.process(image_rgb)\n",
    "        #print(results.face_landmarks)\n",
    "        \n",
    "        # Face_landmarks, pose_landmarks, left_hand_landmarks and right_hand_landmark       \n",
    "        # Recolor back to BGR for rendering image in openCV\n",
    "        image_rgb.flags.writeable = True  # default  perofmance tuner back for openCV\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Mark face landamarks, \n",
    "        mp_drawing.draw_landmarks(image_bgr,\n",
    "                                  results.face_landmarks,\n",
    "                                  mp_holistic.FACE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Mark Right Hand landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.right_hand_landmarks, \n",
    "                                  mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(120,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 3. Mark Left Hand landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.left_hand_landmarks, \n",
    "                                  mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(190,22,76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 4. Mark Pose Landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.pose_landmarks, \n",
    "                                  mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,23), thickness=2, circle_radius=4)\n",
    "                                 )\n",
    "        \n",
    "\n",
    "        # Render back image frame onto the web cam screen\n",
    "        cv2.imshow('Webcam video for Holistic model', image_bgr)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e29750b5-06a9-40ce-b80d-9acab8fff0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obect type of the mediapipe holistic model is:  <class 'mediapipe.python.solution_base.SolutionOutputs'>\n"
     ]
    }
   ],
   "source": [
    "print('obect type of the mediapipe holistic model is: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a88a590a-14a0-4a6b-99d1-d03a141a2fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample co-oridnates of face landmarks from mediapipe [x: 0.5358875393867493\n",
      "y: 0.5039317011833191\n",
      "z: -0.019475294277071953\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('sample co-oridnates of face landmarks from mediapipe', results.face_landmarks.landmark[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89be3859-a871-4ae9-9745-9b960bc613f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample co-oridnates of pose landmarks from mediapipe [x: 0.540930986404419\n",
      "y: 0.44723352789878845\n",
      "z: -1.062204122543335\n",
      "visibility: 1.0\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print('sample co-oridnates of pose landmarks from mediapipe', results.pose_landmarks.landmark[0:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978caeb-5f67-444f-a83b-cb44023dac84",
   "metadata": {},
   "source": [
    " # 2. Capture landmarks & Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b29993e-e155-445e-ac23-d8f5a4225358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ada91c8-5602-4cf0-a0fc-d8234174839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of co-ordinates from face landmarks: = 468\n",
      "total number of co-ordinates from pose landmarks: = 33\n",
      "total number of co-ordinates from face and pose landmarks: = 501\n"
     ]
    }
   ],
   "source": [
    "# get number of co-ordinates from face and pose landmarks individually\n",
    "print('total number of co-ordinates from face landmarks: =', len(results.face_landmarks.landmark))\n",
    "print('total number of co-ordinates from pose landmarks: =', len(results.pose_landmarks.landmark))\n",
    "print('total number of co-ordinates from face and pose landmarks: =', \n",
    "      len(results.face_landmarks.landmark) + len(results.pose_landmarks.landmark)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48c6977c-62c7-404f-8614-f64e9f5e3c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total number of co-ordinates from face and pose landmarks combined together\n",
    "num_coords = len(results.face_landmarks.landmark) + len(results.pose_landmarks.landmark)\n",
    "num_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e58f8b31-a1c1-4eb6-b389-a358cb5001c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create header records for each cordinate and type of class, for each landmarks\n",
    "landmarks=['class']\n",
    "for val in range(1, num_coords+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f683da93-9bfa-450c-9e89-b0d8b6d620dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print first 2 cordinates class typename ['class', 'x1', 'y1', 'z1', 'v1', 'x2', 'y2', 'z2']\n",
      "print last 2 cordinates class typename ['x500', 'y500', 'z500', 'v500', 'x501', 'y501', 'z501', 'v501']\n",
      "print total column names from each cordinates: = 2005\n"
     ]
    }
   ],
   "source": [
    "print('print first 2 cordinates class typename', landmarks[0:8])\n",
    "print('print last 2 cordinates class typename', landmarks[-8:])\n",
    "print('print total column names from each cordinates: =', len(landmarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b534af41-e7d2-490e-8e46-ad0f85ebbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the above header record into a CSV file\n",
    "with open('coords.csv', mode = 'w', newline='') as f:\n",
    "    csv_writer=csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ca200f1-d18e-485e-bdd7-73548e951d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = 'Happy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0bcb618-f05a-4587-9f43-22a55e0740a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # number varies with cameras\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor the image to RGB from BGR, as mediapipe expects it\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Make detections\n",
    "        image_rgb.flags.writeable = False  # for perofmance enhancement for holistic model\n",
    "        results = holistic.process(image_rgb)\n",
    "        #print(results.face_landmarks)\n",
    "        \n",
    "        # Face_landmarks, pose_landmarks, left_hand_landmarks and right_hand_landmark       \n",
    "        # Recolor back to BGR for rendering image in openCV\n",
    "        image_rgb.flags.writeable = True  # default  perofmance tuner back for openCV\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Mark face landamarks, \n",
    "        mp_drawing.draw_landmarks(image_bgr,\n",
    "                                  results.face_landmarks,\n",
    "                                  mp_holistic.FACE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Mark Right Hand landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.right_hand_landmarks, \n",
    "                                  mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(120,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 3. Mark Left Hand landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.left_hand_landmarks, \n",
    "                                  mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(190,22,76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 4. Mark Pose Landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.pose_landmarks, \n",
    "                                  mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,23), thickness=2, circle_radius=4)\n",
    "                                 )\n",
    "        \n",
    "        # Export face and pose co-oridnates to CSV\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(\n",
    "                np.array(\n",
    "                [[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]\n",
    "            ).flatten()\n",
    "            )\n",
    "            \n",
    "            # Extract face landmarks\n",
    "            \n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(\n",
    "                np.array(\n",
    "                [[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]\n",
    "            ).flatten()\n",
    "            )  ### Note: there's no visibility co-oridnate in face_landmarks, its always be zero\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row + face_row\n",
    "            \n",
    "            # Append class name\n",
    "            row.insert(0, class_name)\n",
    "            \n",
    "            # export the above header record into a CSV file\n",
    "            with open('coords.csv', mode = 'a', newline='') as f:\n",
    "                csv_writer=csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                csv_writer.writerow(row)\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Render back image frame onto the web cam screen\n",
    "        cv2.imshow('Webcam video for Holistic model', image_bgr)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ac59ec-33ec-442f-a943-c267423aadb9",
   "metadata": {},
   "source": [
    "# 3. Train custom model using Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95986559-0bc2-479c-86e9-31f2339a9885",
   "metadata": {},
   "source": [
    "   ## 3.1 read csv data and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8eb8151-5865-4088-b4c8-222f16042e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "931a0e63-8fe9-4ae2-8d88-8e39e75576b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cff5882-e474-4316-b74c-15c0e8cbba84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z499</th>\n",
       "      <th>v499</th>\n",
       "      <th>x500</th>\n",
       "      <th>y500</th>\n",
       "      <th>z500</th>\n",
       "      <th>v500</th>\n",
       "      <th>x501</th>\n",
       "      <th>y501</th>\n",
       "      <th>z501</th>\n",
       "      <th>v501</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Victorious</td>\n",
       "      <td>0.491090</td>\n",
       "      <td>0.200832</td>\n",
       "      <td>-0.965884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513681</td>\n",
       "      <td>0.147788</td>\n",
       "      <td>-0.902827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542678</td>\n",
       "      <td>0.124769</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546242</td>\n",
       "      <td>0.121003</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Victorious</td>\n",
       "      <td>0.487840</td>\n",
       "      <td>0.212100</td>\n",
       "      <td>-0.790251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.512450</td>\n",
       "      <td>0.151850</td>\n",
       "      <td>-0.724459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006405</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541039</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.006143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544683</td>\n",
       "      <td>0.137998</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Victorious</td>\n",
       "      <td>0.486357</td>\n",
       "      <td>0.225050</td>\n",
       "      <td>-0.890034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.510885</td>\n",
       "      <td>0.163472</td>\n",
       "      <td>-0.826403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.542500</td>\n",
       "      <td>0.156152</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546043</td>\n",
       "      <td>0.152447</td>\n",
       "      <td>0.006294</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 2005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class        x1        y1        z1   v1        x2        y2  \\\n",
       "0  Victorious  0.491090  0.200832 -0.965884  1.0  0.513681  0.147788   \n",
       "1  Victorious  0.487840  0.212100 -0.790251  1.0  0.512450  0.151850   \n",
       "2  Victorious  0.486357  0.225050 -0.890034  1.0  0.510885  0.163472   \n",
       "\n",
       "         z2   v2        x3  ...      z499  v499      x500      y500      z500  \\\n",
       "0 -0.902827  1.0  0.528294  ... -0.007841   0.0  0.542678  0.124769  0.004716   \n",
       "1 -0.724459  1.0  0.528101  ... -0.006405   0.0  0.541039  0.142056  0.006143   \n",
       "2 -0.826403  1.0  0.526918  ... -0.006337   0.0  0.542500  0.156152  0.006291   \n",
       "\n",
       "   v500      x501      y501      z501  v501  \n",
       "0   0.0  0.546242  0.121003  0.004561   0.0  \n",
       "1   0.0  0.544683  0.137998  0.006125   0.0  \n",
       "2   0.0  0.546043  0.152447  0.006294   0.0  \n",
       "\n",
       "[3 rows x 2005 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdef5bf6-635e-4319-a654-d8dbbf33fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Happy         600\n",
       "Sad           523\n",
       "Victorious    343\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e8f2958-bea8-459c-8c40-e953a89e63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('class', axis=1) # Faatures\n",
    "y=df['class']   # target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ede4c545-b43d-45f2-ac21-f1a1d988caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the landmark dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=43, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46d157dc-d512-465d-9c06-909555c1f76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of Train dataset (1026, 2004)\n",
      "shape of Test dataset (440, 2004)\n"
     ]
    }
   ],
   "source": [
    "print('shape of Train dataset', X_train.shape)\n",
    "print('shape of Test dataset', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e852c9-b00f-4aa4-8bd3-6c456caf2006",
   "metadata": {},
   "source": [
    "## 3.2 train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a06bde4d-eda4-4c33-8b97-3ede0268edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "513aac4b-b2e2-4265-8fd1-b1d1a86129c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'lr':make_pipeline(StandardScaler(), LogisticRegression()),\n",
    "    'rc':make_pipeline(StandardScaler(), RidgeClassifier()),\n",
    "    'rf':make_pipeline(StandardScaler(), RandomForestClassifier()),\n",
    "    'gb':make_pipeline(StandardScaler(), GradientBoostingClassifier()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ac3a7e1-1322-4b97-a584-931b810bf317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/aibd/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "fit_models={}\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = pipeline.fit(X_train, y_train)\n",
    "    fit_models[algo] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b031075-380c-4319-a27a-869869681986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('logisticregression', LogisticRegression())]),\n",
       " 'rc': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('ridgeclassifier', RidgeClassifier())]),\n",
       " 'rf': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('randomforestclassifier', RandomForestClassifier())]),\n",
       " 'gb': Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                 ('gradientboostingclassifier', GradientBoostingClassifier())])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e9716ea-c125-41ec-bb66-805ce7a50209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sad', 'Sad', 'Sad', 'Victorious', 'Sad', 'Victorious',\n",
       "       'Victorious', 'Sad', 'Happy', 'Happy', 'Victorious', 'Victorious',\n",
       "       'Happy', 'Victorious', 'Sad', 'Happy', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'Happy', 'Happy', 'Happy', 'Sad', 'Happy', 'Sad',\n",
       "       'Victorious', 'Sad', 'Happy', 'Sad', 'Sad', 'Happy', 'Sad', 'Sad',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Happy', 'Happy', 'Happy',\n",
       "       'Victorious', 'Sad', 'Happy', 'Happy', 'Victorious', 'Happy',\n",
       "       'Sad', 'Happy', 'Sad', 'Happy', 'Happy', 'Happy', 'Sad',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Sad', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'Sad', 'Victorious', 'Sad', 'Sad', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'Sad',\n",
       "       'Happy', 'Happy', 'Victorious', 'Sad', 'Happy', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Sad', 'Happy', 'Victorious',\n",
       "       'Happy', 'Sad', 'Victorious', 'Sad', 'Happy', 'Happy', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Sad', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Sad', 'Happy', 'Victorious', 'Happy', 'Happy',\n",
       "       'Sad', 'Sad', 'Happy', 'Sad', 'Happy', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Happy', 'Victorious', 'Happy', 'Happy', 'Sad',\n",
       "       'Sad', 'Sad', 'Sad', 'Victorious', 'Happy', 'Sad', 'Victorious',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Victorious', 'Sad', 'Happy', 'Happy', 'Sad',\n",
       "       'Happy', 'Happy', 'Victorious', 'Happy', 'Happy', 'Sad', 'Happy',\n",
       "       'Sad', 'Happy', 'Victorious', 'Happy', 'Happy', 'Sad', 'Sad',\n",
       "       'Happy', 'Happy', 'Sad', 'Happy', 'Happy', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'Happy', 'Happy', 'Sad', 'Sad', 'Sad', 'Victorious',\n",
       "       'Happy', 'Victorious', 'Happy', 'Happy', 'Happy', 'Happy', 'Sad',\n",
       "       'Sad', 'Victorious', 'Sad', 'Victorious', 'Happy', 'Happy',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Victorious', 'Victorious', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Sad', 'Sad', 'Sad', 'Happy', 'Happy',\n",
       "       'Sad', 'Victorious', 'Happy', 'Happy', 'Victorious', 'Happy',\n",
       "       'Happy', 'Happy', 'Sad', 'Sad', 'Sad', 'Sad', 'Happy',\n",
       "       'Victorious', 'Sad', 'Sad', 'Victorious', 'Sad', 'Happy', 'Happy',\n",
       "       'Sad', 'Happy', 'Happy', 'Happy', 'Happy', 'Sad', 'Sad',\n",
       "       'Victorious', 'Happy', 'Sad', 'Sad', 'Happy', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Victorious', 'Happy', 'Sad',\n",
       "       'Victorious', 'Happy', 'Happy', 'Sad', 'Victorious', 'Sad', 'Sad',\n",
       "       'Victorious', 'Happy', 'Happy', 'Victorious', 'Sad', 'Happy',\n",
       "       'Sad', 'Sad', 'Sad', 'Happy', 'Victorious', 'Sad', 'Sad', 'Happy',\n",
       "       'Sad', 'Sad', 'Sad', 'Sad', 'Victorious', 'Happy', 'Sad', 'Sad',\n",
       "       'Happy', 'Victorious', 'Victorious', 'Sad', 'Sad', 'Happy', 'Sad',\n",
       "       'Sad', 'Victorious', 'Sad', 'Happy', 'Sad', 'Sad', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Victorious', 'Sad', 'Happy',\n",
       "       'Victorious', 'Happy', 'Victorious', 'Victorious', 'Victorious',\n",
       "       'Victorious', 'Happy', 'Victorious', 'Sad', 'Happy', 'Sad',\n",
       "       'Happy', 'Victorious', 'Sad', 'Happy', 'Happy', 'Happy', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Victorious', 'Victorious', 'Sad',\n",
       "       'Happy', 'Happy', 'Sad', 'Happy', 'Victorious', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Victorious', 'Happy', 'Happy', 'Happy',\n",
       "       'Victorious', 'Victorious', 'Victorious', 'Sad', 'Sad', 'Happy',\n",
       "       'Happy', 'Happy', 'Sad', 'Sad', 'Happy', 'Victorious',\n",
       "       'Victorious', 'Happy', 'Victorious', 'Happy', 'Happy', 'Sad',\n",
       "       'Happy', 'Sad', 'Sad', 'Happy', 'Happy', 'Sad', 'Happy',\n",
       "       'Victorious', 'Sad', 'Victorious', 'Happy', 'Happy', 'Sad',\n",
       "       'Victorious', 'Happy', 'Sad', 'Victorious', 'Victorious', 'Happy',\n",
       "       'Victorious', 'Sad', 'Sad', 'Sad', 'Happy', 'Sad', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Sad', 'Sad', 'Sad', 'Happy', 'Happy',\n",
       "       'Sad', 'Victorious', 'Sad', 'Happy', 'Happy', 'Sad', 'Victorious',\n",
       "       'Sad', 'Sad', 'Happy', 'Happy', 'Happy', 'Sad', 'Happy', 'Happy',\n",
       "       'Sad', 'Sad', 'Sad', 'Happy', 'Sad', 'Sad', 'Victorious', 'Sad',\n",
       "       'Happy', 'Sad', 'Happy', 'Happy', 'Victorious', 'Happy', 'Happy',\n",
       "       'Happy', 'Sad', 'Happy', 'Victorious', 'Victorious', 'Victorious',\n",
       "       'Victorious', 'Victorious', 'Happy', 'Happy', 'Happy', 'Happy',\n",
       "       'Happy', 'Happy', 'Sad', 'Happy', 'Sad', 'Victorious', 'Sad',\n",
       "       'Sad', 'Happy', 'Happy', 'Victorious', 'Sad', 'Sad', 'Happy',\n",
       "       'Sad', 'Sad', 'Victorious', 'Sad', 'Happy', 'Victorious', 'Sad',\n",
       "       'Victorious', 'Sad', 'Happy'], dtype='<U10')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions on test dataset example\n",
    "fit_models['rc'].predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96602010-452b-4d5f-88ef-99080a30bc74",
   "metadata": {},
   "source": [
    "   ## 3.3 Evaluate & Serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21383ca5-6767-47c3-ba4d-fed25944fe1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5607b1c9-75cc-4853-a37a-b90bc4ede8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9863636363636363\n",
      "rc 0.9818181818181818\n",
      "rf 0.9840909090909091\n",
      "gb 0.990909090909091\n"
     ]
    }
   ],
   "source": [
    "for algo, model in fit_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(algo, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26b3fdb6-a698-4134-8787-3d91a9ec6f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model, which random forest here\n",
    "with open('body_language.pkl', 'wb') as f:\n",
    "    pickle.dump(fit_models['rf'], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac190b5-025d-4b0e-9e90-f2907c7633b2",
   "metadata": {},
   "source": [
    "   ## 4. Make detections with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21c5a023-79f9-43d2-94e6-5d822eff6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adbe0461-de64-4534-bfd3-787a2e6b3fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the saved model\n",
    "with open('body_language.pkl', 'rb')  as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abf23336-d7ae-446b-bb5c-429b1ecfd37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('randomforestclassifier', RandomForestClassifier())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff60ba03-e9ec-48d5-a4c1-464cc7096451",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) # number varies with cameras\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor the image to RGB from BGR, as mediapipe expects it\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Make detections\n",
    "        image_rgb.flags.writeable = False  # for perofmance enhancement for holistic model\n",
    "        results = holistic.process(image_rgb)\n",
    "        #print(results.face_landmarks)\n",
    "        \n",
    "        # Face_landmarks, pose_landmarks, left_hand_landmarks and right_hand_landmark       \n",
    "        # Recolor back to BGR for rendering image in openCV\n",
    "        image_rgb.flags.writeable = True  # default  perofmance tuner back for openCV\n",
    "        image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # 1. Mark face landamarks, \n",
    "        mp_drawing.draw_landmarks(image_bgr,\n",
    "                                  results.face_landmarks,\n",
    "                                  mp_holistic.FACE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(80,110,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,256,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Mark Right Hand landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.right_hand_landmarks, \n",
    "                                  mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(120,22,10), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 3. Mark Left Hand landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.left_hand_landmarks, \n",
    "                                  mp_holistic.HAND_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(190,22,76), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        # 4. Mark Pose Landmarks\n",
    "        mp_drawing.draw_landmarks(image_bgr, \n",
    "                                  results.pose_landmarks, \n",
    "                                  mp_holistic.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                  mp_drawing.DrawingSpec(color=(245,66,23), thickness=2, circle_radius=4)\n",
    "                                 )\n",
    "        \n",
    "        # Export face and pose co-oridnates to CSV\n",
    "        try:\n",
    "            # Extract pose landmarks\n",
    "            pose = results.pose_landmarks.landmark\n",
    "            pose_row = list(\n",
    "                np.array(\n",
    "                [[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in pose]\n",
    "            ).flatten()\n",
    "            )\n",
    "            \n",
    "            # Extract face landmarks\n",
    "            \n",
    "            face = results.face_landmarks.landmark\n",
    "            face_row = list(\n",
    "                np.array(\n",
    "                [[landmark.x, landmark.y, landmark.z, landmark.visibility] for landmark in face]\n",
    "            ).flatten()\n",
    "            )  ### Note: there's no visibility co-oridnate in face_landmarks, its always be zero\n",
    "            \n",
    "            # Concate rows\n",
    "            row = pose_row + face_row\n",
    "            \n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_probability = model.predict_proba(X)[0]  # probability of correct classification\n",
    "            \n",
    "            # print \n",
    "            #print(body_language_class, body_language_probability)\n",
    "            \n",
    "            # Grab Ear co-ordinates\n",
    "            coords = tuple(\n",
    "                np.multiply(\n",
    "                    np.array(\n",
    "                        (results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].x,\n",
    "                         results.pose_landmarks.landmark[mp_holistic.PoseLandmark.LEFT_EAR].y)\n",
    "                    ),[640, 480]\n",
    "                )\n",
    "                .astype(int))\n",
    "            \n",
    "            cv2.rectangle(image_bgr,\n",
    "                          (coords[0], coords[1]+5),\n",
    "                          (coords[0]+len(body_language_class)*10,coords[1]-30),\n",
    "                          (245,117, 16), -1)\n",
    "            cv2.putText(image_bgr, \n",
    "                        body_language_class, \n",
    "                        coords,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1,\n",
    "                        (255, 255, 255),\n",
    "                        2,\n",
    "                        cv2.LINE_AA\n",
    "                       )\n",
    "            \n",
    "            \n",
    "            # Add Status Box\n",
    "            cv2.rectangle(image_bgr,(0,0),(250,60),(245,117, 16), -1)\n",
    "            \n",
    "            # Display CLASS\n",
    "            cv2.putText(image_bgr,'CLASS',(95,12),cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0, 0, 0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image_bgr,body_language_class.split(' ')[0],\n",
    "                        (90,40),cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 255),2,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "            \n",
    "            # Display Prediction Probability\n",
    "            cv2.putText(image_bgr,'PROB',(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0, 0, 0),1,cv2.LINE_AA)\n",
    "            cv2.putText(image_bgr,str(round(body_language_probability[np.argmax(body_language_probability)],2)),\n",
    "                        (10,40),cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 255),2,cv2.LINE_AA)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # Render back image frame onto the web cam screen\n",
    "        cv2.imshow('Webcam video for Holistic model', image_bgr)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b7ac43-3064-4c7b-a7aa-efebbc6b1891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
